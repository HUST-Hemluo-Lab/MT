{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data source: https://huggingface.co/datasets/sagawa/pubchem-10m-canonicalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import Import\n",
    "from tkinter import YES\n",
    "from xml.parsers.expat import model\n",
    "from translation_smi4decoder_with_mask import TrfmSeq2seq\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "from build_vocab import WordVocab\n",
    "from torch.utils import data\n",
    "import pandas as pd \n",
    "import math\n",
    "import numpy as np\n",
    "import collections\n",
    "import copy\n",
    "from typing import Callable, List\n",
    "from torch.autograd import Variable\n",
    "from collections import namedtuple\n",
    "from utils_attention_visiualization import visualize_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from train.TranslationModel import TrfmSeq2seq_pubchem\n",
    "Hypothesis = namedtuple('Hypothesis', ['value', 'score'])\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# device = 'cpu'\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "src_vocab = WordVocab.load_vocab('data/pubchem/smi_vocab1.pkl')\n",
    "tgt_vocab = WordVocab.load_vocab('data/pubchem/pharm_vocab1.pkl')\n",
    "inchi_vocab = WordVocab.load_vocab('data/pubchem/inchi_vocab1.pkl')\n",
    "pubchemfp_vocab = WordVocab.load_vocab('data/pubchem/pubfp_vocab1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_nmt(text):\n",
    "    source, target = [], []\n",
    "    for i in tqdm(range(len(text)),desc='tokenize_nmt进度:'):\n",
    "        line = text[i].strip('\\n').strip(' ')\n",
    "        parts = line.split('\\t')\n",
    "        if len(parts) == 2:\n",
    "            source.append(parts[0].split(' '))\n",
    "            target.append(parts[1].split(' '))\n",
    "    return source, target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sm(sm):\n",
    "    '''\n",
    "    function: Split SMILES into words. Care for Cl, Br, Si, Se, Na etc.\n",
    "    input: A SMILES\n",
    "    output: A string with space between words\n",
    "    '''\n",
    "    arr = []\n",
    "    i = 0\n",
    "    while i < len(sm)-1:\n",
    "        if not sm[i] in ['%', 'C', 'B', 'S', 'N', 'R', 'X', 'L', 'A', 'M', \\\n",
    "                        'T', 'Z', 's', 't', 'H', '+', '-', 'K', 'F']:\n",
    "            arr.append(sm[i])\n",
    "            i += 1\n",
    "        elif sm[i]=='%':\n",
    "            arr.append(sm[i:i+3])\n",
    "            i += 3\n",
    "        elif sm[i]=='C' and sm[i+1]=='l':\n",
    "            arr.append(sm[i:i+2])\n",
    "            i += 2\n",
    "        elif sm[i]=='C' and sm[i+1]=='a':\n",
    "            arr.append(sm[i:i+2])\n",
    "            i += 2\n",
    "        elif sm[i]=='C' and sm[i+1]=='u':\n",
    "            arr.append(sm[i:i+2])\n",
    "            i += 2\n",
    "        elif sm[i]=='B' and sm[i+1]=='r':\n",
    "            arr.append(sm[i:i+2])\n",
    "            i += 2\n",
    "        elif sm[i]=='B' and sm[i+1]=='e':\n",
    "            arr.append(sm[i:i+2])\n",
    "            i += 2\n",
    "        elif sm[i]=='B' and sm[i+1]=='a':\n",
    "            arr.append(sm[i:i+2])\n",
    "            i += 2\n",
    "        elif sm[i]=='B' and sm[i+1]=='i':\n",
    "            arr.append(sm[i:i+2])\n",
    "            i += 2\n",
    "        elif sm[i]=='S' and sm[i+1]=='i':\n",
    "            arr.append(sm[i:i+2])\n",
    "            i += 2\n",
    "        elif sm[i]=='S' and sm[i+1]=='e':\n",
    "            arr.append(sm[i:i+2])\n",
    "            i += 2\n",
    "        elif sm[i]=='S' and sm[i+1]=='r':\n",
    "            arr.append(sm[i:i+2])\n",
    "            i += 2\n",
    "        elif sm[i]=='N' and sm[i+1]=='a':\n",
    "            arr.append(sm[i:i+2])\n",
    "            i += 2\n",
    "        elif sm[i]=='N' and sm[i+1]=='i':\n",
    "            arr.append(sm[i:i+2])\n",
    "            i += 2\n",
    "        elif sm[i]=='R' and sm[i+1]=='b':\n",
    "            arr.append(sm[i:i+2])\n",
    "            i += 2\n",
    "        elif sm[i]=='R' and sm[i+1]=='a':\n",
    "            arr.append(sm[i:i+2])\n",
    "            i += 2\n",
    "        elif sm[i]=='X' and sm[i+1]=='e':\n",
    "            arr.append(sm[i:i+2])\n",
    "            i += 2\n",
    "        elif sm[i]=='L' and sm[i+1]=='i':\n",
    "            arr.append(sm[i:i+2])\n",
    "            i += 2\n",
    "        elif sm[i]=='A' and sm[i+1]=='l':\n",
    "            arr.append(sm[i:i+2])\n",
    "            i += 2\n",
    "        elif sm[i]=='A' and sm[i+1]=='s':\n",
    "            arr.append(sm[i:i+2])\n",
    "            i += 2\n",
    "        elif sm[i]=='A' and sm[i+1]=='g':\n",
    "            arr.append(sm[i:i+2])\n",
    "            i += 2\n",
    "        elif sm[i]=='A' and sm[i+1]=='u':\n",
    "            arr.append(sm[i:i+2])\n",
    "            i += 2\n",
    "        elif sm[i]=='M' and sm[i+1]=='g':\n",
    "            arr.append(sm[i:i+2])\n",
    "            i += 2\n",
    "        elif sm[i]=='M' and sm[i+1]=='n':\n",
    "            arr.append(sm[i:i+2])\n",
    "            i += 2\n",
    "        elif sm[i]=='T' and sm[i+1]=='e':\n",
    "            arr.append(sm[i:i+2])\n",
    "            i += 2\n",
    "        elif sm[i]=='Z' and sm[i+1]=='n':\n",
    "            arr.append(sm[i:i+2])\n",
    "            i += 2\n",
    "        elif sm[i]=='s' and sm[i+1]=='i':\n",
    "            arr.append(sm[i:i+2])\n",
    "            i += 2\n",
    "        elif sm[i]=='s' and sm[i+1]=='e':\n",
    "            arr.append(sm[i:i+2])\n",
    "            i += 2\n",
    "        elif sm[i]=='t' and sm[i+1]=='e':\n",
    "            arr.append(sm[i:i+2])\n",
    "            i += 2\n",
    "        elif sm[i]=='H' and sm[i+1]=='e':\n",
    "            arr.append(sm[i:i+2])\n",
    "            i += 2\n",
    "        elif sm[i]=='+' and sm[i+1]=='2':\n",
    "            arr.append(sm[i:i+2])\n",
    "            i += 2\n",
    "        elif sm[i]=='+' and sm[i+1]=='3':\n",
    "            arr.append(sm[i:i+2])\n",
    "            i += 2\n",
    "        elif sm[i]=='+' and sm[i+1]=='4':\n",
    "            arr.append(sm[i:i+2])\n",
    "            i += 2\n",
    "        elif sm[i]=='-' and sm[i+1]=='2':\n",
    "            arr.append(sm[i:i+2])\n",
    "            i += 2\n",
    "        elif sm[i]=='-' and sm[i+1]=='3':\n",
    "            arr.append(sm[i:i+2])\n",
    "            i += 2\n",
    "        elif sm[i]=='-' and sm[i+1]=='4':\n",
    "            arr.append(sm[i:i+2])\n",
    "            i += 2\n",
    "        elif sm[i]=='K' and sm[i+1]=='r':\n",
    "            arr.append(sm[i:i+2])\n",
    "            i += 2\n",
    "        elif sm[i]=='F' and sm[i+1]=='e':\n",
    "            arr.append(sm[i:i+2])\n",
    "            i += 2\n",
    "        else:\n",
    "            arr.append(sm[i])\n",
    "            i += 1\n",
    "    if i == len(sm)-1:\n",
    "        arr.append(sm[i])\n",
    "    return ' '.join(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz, device):\n",
    "        mask = (torch.triu(torch.ones((sz, sz), device=device)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "def build_array_nmt(lines, vocab, num_steps):\n",
    "    A,masks = [],[]\n",
    "    for i in range(len(lines)):\n",
    "        line = lines[i]\n",
    "        content = [vocab.stoi.get(token, vocab.unk_index) for token in line]\n",
    "        if len(content) > num_steps -2 : \n",
    "            content = content[:254]\n",
    "        X = content + [vocab.eos_index]\n",
    "        masks.append([False for _ in range(len(X))] + [True for _ in range(num_steps - len(X))])\n",
    "        padding = [vocab.pad_index]*(num_steps - len(X))\n",
    "        X.extend(padding)\n",
    "        # array = torch.tensor([truncate_pad(l, num_steps, vocab.pad_index) for l in lines])\n",
    "        A.append(copy.deepcopy(X))\n",
    "    return torch.tensor(A), torch.tensor(masks)\n",
    "\n",
    "def load_array(data_arrays, batch_size, is_train=True): #@save\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    "\n",
    "def truncate_pad(line, num_steps, padding_token):\n",
    "    if len(line) > num_steps:\n",
    "        return line[:num_steps] # 截断\n",
    "    return line + [padding_token] * (num_steps - len(line)) # 填充\n",
    "\n",
    "def get_dataset(text, src_vocab, tgt_vocab,seq_len):\n",
    "    source,target = tokenize_nmt(text)\n",
    "    target, tgt_valid_len = build_array_nmt(target, tgt_vocab, num_steps=seq_len) \n",
    "    source, src_valid_len = build_array_nmt(source, src_vocab, num_steps=seq_len) \n",
    "    dataset = (source, src_valid_len, target, tgt_valid_len)\n",
    "    return dataset\n",
    "\n",
    "def greedy_decode(mode,model, src, max_len, start_symbol ):\n",
    "\n",
    "    src = src.cuda()\n",
    "    src_mask = (src == src_vocab.pad_index).transpose(0,1).cuda()\n",
    "    memory = model.Encoder(src,src_mask).cuda()  \n",
    "    ys = torch.ones(1, 1).fill_(start_symbol). \\\n",
    "        type(torch.long).cuda()\n",
    "    \n",
    "    for i in range(max_len - 1):\n",
    "       \n",
    "        memory = memory.cuda()\n",
    "\n",
    "        if mode == 1:\n",
    "            out = model.Decoder1(ys,memory,src_mask)\n",
    "            out = out.transpose(0, 1) \n",
    "            prob = model.out1(out[:, -1])\n",
    "        if mode == 2:\n",
    "            out = model.Decoder2(ys,memory,src_mask)\n",
    "            out = out.transpose(0, 1)\n",
    "            prob = model.out2(out[:, -1]) \n",
    "        if mode == 3:\n",
    "            out = model.Decoder3(ys,memory,src_mask)\n",
    "            out = out.transpose(0, 1)\n",
    "            prob = model.out3(out[:, -1]) \n",
    "        if mode == 4:\n",
    "            out = model.Decoder4(ys,memory,src_mask)\n",
    "            out = out.transpose(0, 1)\n",
    "            prob = model.out4(out[:, -1]) \n",
    "\n",
    "        _, next_word = torch.max(prob, dim=1)  # 选Choose the one with the maximum probability\n",
    "        next_word = next_word.item()\n",
    "        ys = torch.cat([ys, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        # The predictive output decoded at the current moment is stacked with all previous results as input to predict the next word\n",
    "        if next_word == src_vocab.eos_index:  # If the output for the current moment is eos, end the loop.\n",
    "            break\n",
    "    return ys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(model, src, mode):\n",
    "    model.eval()\n",
    "    src_token = split_sm(src).split()\n",
    "    tokens = [src_vocab.stoi.get(token, src_vocab.unk_index) for token in src_token]\n",
    "    if len(tokens) > 254 : \n",
    "            tokens = tokens[:254]\n",
    "    tokens = tokens + [src_vocab.eos_index]\n",
    "    src_tokens = truncate_pad(tokens,256, src_vocab.pad_index)\n",
    "    num_tokens = len(tokens)\n",
    "    src = torch.t(torch.tensor(src_tokens).unsqueeze(0)).cuda()\n",
    "    tgt_tokens = greedy_decode(mode,model, src, max_len=256,start_symbol=tgt_vocab.sos_index).flatten() \n",
    "\n",
    "    if mode == 1:\n",
    "        return \" \".join([tgt_vocab.itos[tok] for tok in tgt_tokens]).replace(\"<sos>\", \"\").replace(\"<eos>\", \"\")\n",
    "    if mode == 2:\n",
    "        return \" \".join([src_vocab.itos[tok] for tok in tgt_tokens]).replace(\"<sos>\", \"\").replace(\"<eos>\", \"\")\n",
    "    if mode == 3:\n",
    "        return \" \".join([inchi_vocab.itos[tok] for tok in tgt_tokens]).replace(\"<sos>\", \"\").replace(\"<eos>\", \"\")\n",
    "    if mode == 4:\n",
    "        return \" \".join([pubchemfp_vocab.itos[tok] for tok in tgt_tokens]).replace(\"<sos>\", \"\").replace(\"<eos>\", \"\")\n",
    "\n",
    "\n",
    "def translate_smi_to_pharm(mode,srcs, hidden_size,n_heads,n_layers):\n",
    "\n",
    "    translation_model = TrfmSeq2seq(len(src_vocab),hidden_size, len(tgt_vocab), len(src_vocab),\n",
    "                                         len(inchi_vocab), len(pubchemfp_vocab), \n",
    "                                         n_heads,\n",
    "                                         n_layers,\n",
    "                                         )\n",
    "\n",
    "    translation_model.eval()\n",
    "    translation_model = translation_model.cuda()\n",
    "\n",
    "    loaded_paras = torch.load('trfm_new_98_10000.pkl') \n",
    "    translation_model.load_state_dict(loaded_paras)\n",
    "    results = []\n",
    "    for src in tqdm(srcs):\n",
    "        r = translate(translation_model, src, mode)\n",
    "        # r = predict_seq2seq(translation_model, src)\n",
    "        results.append(r)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu(pred_tokens, label_tokens, k):\n",
    "    \"\"\"calculate BLEU\"\"\"\n",
    "    len_pred, len_label = len(pred_tokens), len(label_tokens)\n",
    "    score = math.exp(min(0, 1 - len_label / len_pred))\n",
    "    for n in range(1, k + 1):\n",
    "        num_matches, label_subs = 0, collections.defaultdict(int)\n",
    "        for i in range(len_label - n + 1):\n",
    "            label_subs[''.join(label_tokens[i: i + n])] += 1\n",
    "        for i in range(len_pred - n + 1):\n",
    "            if label_subs[''.join(pred_tokens[i: i + n])] > 0:\n",
    "                num_matches += 1\n",
    "                label_subs[''.join(pred_tokens[i: i + n])] -= 1\n",
    "        # try:\n",
    "        score *= math.pow(num_matches / (len_pred - n + 1), math.pow(0.5, n))\n",
    "        # except:\n",
    "        #     score = 0\n",
    "    return score\n",
    "\n",
    "def predict(srcs, mode):\n",
    "    results = translate_smi_to_pharm(mode,srcs, hidden_size=256,n_heads=4,n_layers=2)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_golden_st(task):\n",
    "    data = corpus[task]\n",
    "    results = []\n",
    "    for i in range(len(data)):\n",
    "        results.append(data[i].split(' '))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileph = 'data/transltation_test/smi_pharm_inchi_corpus1.txt'\n",
    "corpus = pd.read_csv(fileph,delimiter=\"\\t\",header=None)\n",
    "corpus.columns = ['smiles','pharm','inchi','pubchemfp']\n",
    "srcs = get_golden_st('smiles')\n",
    "pharm = get_golden_st('pharm')\n",
    "inchi = get_golden_st('inchi')\n",
    "pubchemfp = get_golden_st('pubchemfp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71009/71009 [25:19:02<00:00,  1.28s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7437027200383395 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71009/71009 [13:36:16<00:00,  1.45it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9998477311422149 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71009/71009 [25:33:29<00:00,  1.30s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7381593471383687 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71009/71009 [46:48:41<00:00,  2.37s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.968787643673169 4\n"
     ]
    }
   ],
   "source": [
    "for mode in [1,2,3,4]:    \n",
    "    results = predict(srcs,mode)\n",
    "    output = []\n",
    "    for i in range(len(results)):\n",
    "        output.append(results[i].split(' ')[1:-1])\n",
    "    BLUE = []\n",
    "\n",
    "    for i in range(len(output)):\n",
    "        # print(f'bleu {bleu(output[i], pharm[i], k=3):.3f}')\n",
    "        if mode == 1:\n",
    "            try:\n",
    "                BLUE.append(bleu(output[i], pharm[i], k=1))\n",
    "            except:\n",
    "                continue\n",
    "        if mode == 2: \n",
    "            try:\n",
    "                BLUE.append(bleu(output[i], srcs[i], k=3))    \n",
    "            except:\n",
    "                continue\n",
    "        if mode == 3:\n",
    "            try:\n",
    "                BLUE.append(bleu(output[i], inchi[i], k=3))\n",
    "            except:\n",
    "                continue\n",
    "        if mode == 4:\n",
    "            try:\n",
    "                BLUE.append(bleu(output[i], pubchemfp[i], k=1))\n",
    "            except:\n",
    "                continue\n",
    "    print(np.mean(BLUE), mode)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-rdkit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
